{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJw_uBh3YKK-",
        "outputId": "78f298dc-6aba-4e3a-dd5e-7618c62fba8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 18 16:37:34 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check if the GPU is working properly\n",
        "!nvidia-smi\n",
        "%rm -rf ./sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i64M4J0yvKM",
        "outputId": "fd1d51d9-cfe4-4c7a-e1ca-f6a8a9eb7781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.10/dist-packages (1.4.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies\n",
        "%pip install numba -q\n",
        "%pip install engineering-notation -q\n",
        "%pip install opencv-contrib-python -q\n",
        "%pip install argcomplete -q\n",
        "%pip install dv-processing -q\n",
        "%pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBQcrxkczNKS",
        "outputId": "66826c6c-80e2-413d-d89b-e3ae3deda1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'v2e' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone SensorsINI/v2e into colab\n",
        "!git clone https://github.com/SensorsINI/v2e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdIBdsq-zQKh",
        "outputId": "bd0d4a01-a964-4ca1-966b-c38b36850d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/v2e\n",
            "Processing /content/v2e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: argcomplete in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (3.5.1)\n",
            "Requirement already satisfied: engineering-notation in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (4.66.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (4.10.0.84)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (3.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.19.1+cu121)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.60.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (3.7.1)\n",
            "Requirement already satisfied: plyer in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (2.1.0)\n",
            "Requirement already satisfied: screeninfo in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.8.1)\n",
            "Requirement already satisfied: easygui in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.98.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from v2e==1.5.1) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->v2e==1.5.1) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->v2e==1.5.1) (0.43.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->v2e==1.5.1) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->v2e==1.5.1) (3.4)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->v2e==1.5.1) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->v2e==1.5.1) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->v2e==1.5.1) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->v2e==1.5.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->v2e==1.5.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->v2e==1.5.1) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->v2e==1.5.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->v2e==1.5.1) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->v2e==1.5.1) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->v2e==1.5.1) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->v2e==1.5.1) (1.3.0)\n",
            "Building wheels for collected packages: v2e\n",
            "  Building wheel for v2e (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for v2e: filename=v2e-1.5.1-py3-none-any.whl size=116981 sha256=37e628ae099416a25426663b301ceaa91677540a4ad3084daa3f6b3b90380a58\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7x41leru/wheels/77/5f/75/585e5c0362b6f0da630814aee1b3cce77ba29bfd5274e7fa38\n",
            "Successfully built v2e\n",
            "Installing collected packages: v2e\n",
            "  Attempting uninstall: v2e\n",
            "    Found existing installation: v2e 1.5.1\n",
            "    Uninstalling v2e-1.5.1:\n",
            "      Successfully uninstalled v2e-1.5.1\n",
            "Successfully installed v2e-1.5.1\n"
          ]
        }
      ],
      "source": [
        "# install v2e\n",
        "%cd /content/v2e\n",
        "%pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctz0It643gQ9",
        "outputId": "17c53e2f-1fc5-48fb-dc9d-e11b83ff367d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount with goole drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlPeu75L5T0w",
        "outputId": "2a82287a-69cc-4d6c-8f27-0f68e4001fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using GPU: Tesla T4\n",
            "Using GPU: Tesla T4\n",
            "Using GPU: Tesla T4\n",
            "Using GPU: Tesla T4\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "\n",
            "Success: 31\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 876\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 145\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 640\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 207\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 754\n",
            "Output:\n",
            "\n",
            "Success: 1527\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 1070\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 59\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 891\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 641\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 577\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 159\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 755\n",
            "Output:\n",
            "\n",
            "Success: 1697\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 1173\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 141\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 925\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 744\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 622\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4Success: 173\n",
            "Output:\n",
            "\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 1878\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 1204\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 799\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 1924\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2235\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2439\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2927\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2560\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3021\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3315\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3512\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2300\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2172\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2709\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2934\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3399\n",
            "Output:\n",
            "\n",
            "Success: 3092\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2521\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3732\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2340\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2214\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2748\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 2951\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3174\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3791\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3457\n",
            "Output:\n",
            "\n",
            "Success: 2556\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3809\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4005\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4310\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4521\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4957\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5180\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5516\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5447\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3875\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4189\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4330\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4901\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5082\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5262\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5586\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5460\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 3889\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4220\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4442\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 4905\n",
            "Output:\n",
            "\n",
            "Success: 5143\n",
            "Output:\n",
            "\n",
            "Success: 5388\n",
            "Output:\n",
            "\n",
            "Success: 5631\n",
            "Output:\n",
            "\n",
            "Success: 5498\n",
            "Output:\n",
            "\n",
            "Success: 5643\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 6075\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 6596\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 5818\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 6159\n",
            "Output:\n",
            "\n",
            "\n",
            "Using GPU: Tesla T4\n",
            "Success: 6623\n",
            "Output:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import multiprocessing\n",
        "import subprocess\n",
        "import GPUtil\n",
        "import torch\n",
        "\n",
        "# File paths\n",
        "names_file_path = \"/content/stop2.txt\"\n",
        "input_dir = \"/content/drive/MyDrive/V2E/31-6623\"\n",
        "output_dir = \"/content/drive/MyDrive/V2E/output\"\n",
        "\n",
        "def init_gpu():\n",
        "    \"\"\"Initialize GPU for PyTorch or TensorFlow usage.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"\\nUsing GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"\\nUsing CPU\")\n",
        "    return device\n",
        "\n",
        "def process_image_sequence(name):\n",
        "    \"\"\"Process the image sequence and generate event data using v2e.\"\"\"\n",
        "    name = name.strip()\n",
        "    path = os.path.join(input_dir, name)\n",
        "    output_folder = os.path.join(output_dir, name)\n",
        "\n",
        "    # v2e command options\n",
        "    overwrite = True\n",
        "    unique_output_folder = True\n",
        "    out_filename = \"events.h5\"\n",
        "    davis_output = True\n",
        "\n",
        "    skip_video_output = False\n",
        "    dvs_exposure = \"duration .033\"\n",
        "    output_mode = \"dvs128\"\n",
        "\n",
        "    input_frame_rate = 12\n",
        "    input_slowmotion_factor = 1\n",
        "\n",
        "    timestamp_resolution = 0.001\n",
        "    auto_timestamp_resolution = True\n",
        "\n",
        "    # Event thresholds and noise settings\n",
        "    condition = \"Clean\"\n",
        "    thres, sigma, cutoff_hz, leak_rate_hz, shot_noise_rate_hz = (0.2, 0.03, 200, 5.18, 2.716)\n",
        "\n",
        "    if condition == \"Clean\":\n",
        "        thres, sigma, cutoff_hz, leak_rate_hz, shot_noise_rate_hz = (0.2, 0.02, 0, 0, 0)\n",
        "\n",
        "    # Build the v2e command\n",
        "    v2e_command = [\n",
        "        \"v2e\", \"-i\", path, \"-o\", output_folder,\n",
        "        \"--overwrite\" if overwrite else \"\",\n",
        "        \"--unique_output_folder\", str(unique_output_folder).lower(),\n",
        "        \"--dvs_h5\", out_filename,\n",
        "        \"--davis_output\" if davis_output else \"\",\n",
        "        \"--no_preview\",\n",
        "        \"--skip_video_output\" if skip_video_output else f\"--dvs_exposure {dvs_exposure}\",\n",
        "        \"--input_frame_rate\", str(input_frame_rate),\n",
        "        \"--input_slowmotion_factor\", str(input_slowmotion_factor),\n",
        "        \"--disable_slomo\",\n",
        "        \"--auto_timestamp_resolution\", \"true\" if auto_timestamp_resolution else \"false\",\n",
        "        \"--pos_thres\", str(thres),\n",
        "        \"--neg_thres\", str(thres),\n",
        "        \"--sigma_thres\", str(sigma),\n",
        "        \"--cutoff_hz\", str(cutoff_hz),\n",
        "        \"--leak_rate_hz\", str(leak_rate_hz),\n",
        "        \"--shot_noise_rate_hz\", str(shot_noise_rate_hz),\n",
        "        f\"--{output_mode}\"\n",
        "    ]\n",
        "\n",
        "    # Remove empty string arguments\n",
        "    v2e_command = list(filter(None, v2e_command))\n",
        "\n",
        "    # Run the command\n",
        "    try:\n",
        "        result = subprocess.run(\" \".join(v2e_command), shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "        print(f\"Success: {name}\\nOutput:\\n{result.stdout.decode()}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error processing {name}:\\n{e.stderr.decode()}\")\n",
        "\n",
        "def process_image_sequence_in_colab(name):\n",
        "    \"\"\"Process video with GPU management in Google Colab.\"\"\"\n",
        "    # Ensure GPU is available and select it\n",
        "    gpu_id = GPUtil.getFirstAvailable()[0]\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
        "    init_gpu()  # Initialize GPU (useful for other tasks)\n",
        "\n",
        "    process_image_sequence(name)\n",
        "\n",
        "# Read names from the file\n",
        "with open(names_file_path, \"r\") as file:\n",
        "    names = file.readlines()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Limit parallelism to 4-8 processes to avoid GPU contention\n",
        "    num_cpus = 8\n",
        "\n",
        "    with multiprocessing.Pool(num_cpus) as pool:\n",
        "        pool.map(process_image_sequence_in_colab, names)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}